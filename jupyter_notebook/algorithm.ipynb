{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 9 3 5 1 3\n",
      "[1, 3, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "'''Quick sort'''\n",
    "\n",
    "def quick_sort(arr):\n",
    "    if len(arr)<=1:\n",
    "        return arr\n",
    "    else:\n",
    "        m = arr[0]\n",
    "        lower =[]\n",
    "        grater = []\n",
    "        for i in arr[1:]:\n",
    "            if i>m:\n",
    "                grater.append(i)\n",
    "            else:\n",
    "                lower.append(i)\n",
    "    return quick_sort(lower)+[m]+quick_sort(grater)\n",
    "\n",
    "a = list(map(int,input().split()))\n",
    "print(quick_sort(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'no': 384, b'yes': 640}\n",
      "{b'yes': 256}\n",
      "{b'no': 256, b'yes': 128}\n",
      "{b'no': 128, b'yes': 256}\n",
      "{b'no': 192, b'yes': 288}\n",
      "{b'no': 128, b'yes': 160}\n",
      "{b'no': 64, b'yes': 192}\n",
      "{b'no': 64, b'yes': 420}\n",
      "{b'no': 320, b'yes': 220}\n",
      "{b'no': 192, b'yes': 160}\n",
      "{b'no': 192, b'yes': 480}\n",
      "{'credit': {b'no': b'no', b'yes': b'yes'}}\n"
     ]
    }
   ],
   "source": [
    "'''Decision Tree'''\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "class decision_tree:\n",
    "    def __init__(self):\n",
    "        self.tree = {}\n",
    "        self.dataset = []\n",
    "        self.labels = []\n",
    "\n",
    "    def load_dataset(self,path,labels):\n",
    "        fp = open(path,'rb')\n",
    "        content = fp.read()\n",
    "        fp.close()\n",
    "        rowlist = content.splitlines()\n",
    "        recordlist = [row.split(\"\\t\".encode()) for row in rowlist if row.strip()]\n",
    "        self.dataset = recordlist\n",
    "        self.labels = labels\n",
    "    \n",
    "    def split_dataset(self,dataset,i,subfeat):\n",
    "        # At first I extract the subfeature column and the label column,it's useful in the \n",
    "        # function 'getBestFeat',but it doesn't work in the fuction 'built_tree'\n",
    "        \"\"\"column_i_l = [[data[i],data[-1]] for data in dataset]\n",
    "        subdata = [data for data in column_i_l if data[0] == subfeat]\n",
    "        return subdata\n",
    "        \"\"\"\n",
    "        rtdataset = []\n",
    "        for data in dataset:\n",
    "            if data[i] == subfeat:\n",
    "                temp = data[:i]\n",
    "                temp.extend(data[i+1:])\n",
    "                rtdataset.append(temp)\n",
    "        return rtdataset\n",
    "    \n",
    "    #calculate the information entropy\n",
    "    def information_entropy(self,dataset):\n",
    "        datalen = len(dataset)\n",
    "        catalist = [data[-1] for data in dataset]#get the label column\n",
    "        catagory = list(set(catalist))#get the catagory\n",
    "        info_entropy = 0.0\n",
    "        items = dict([(i,catalist.count(i)) for i in catagory])#get the number of every category\n",
    "        #compute information entropy\n",
    "        print(items)\n",
    "        for key in items:\n",
    "            prob = items[key] / datalen\n",
    "            info_entropy -= prob * math.log(prob,2)\n",
    "        return info_entropy\n",
    "    \n",
    "    def getBestFeat(self,dataset):\n",
    "        featlen = len(dataset[0]) - 1 #get the number of features\n",
    "        baseEntropy = self.information_entropy(dataset)\n",
    "        bestinfoGain = 0.0\n",
    "        bestFeat = -1\n",
    "        for i in range(featlen):\n",
    "            newEntropy = 0.0\n",
    "            catalist = set([data[i] for data in dataset])\n",
    "            for subfeat in catalist:\n",
    "                subdata = self.split_dataset(dataset,i,subfeat)\n",
    "                prob = len(subdata) / len(dataset)\n",
    "                newEntropy += self.information_entropy(subdata)\n",
    "            infoGain = baseEntropy - newEntropy\n",
    "            if infoGain > bestinfoGain:\n",
    "                bestinfoGain = infoGain\n",
    "                bestFeat = i\n",
    "        return bestFeat\n",
    "    def maxlabels(self,catalist):\n",
    "        # my method\n",
    "        \"\"\"catalist = [data[-1] for data in dataset]\n",
    "        labellist = set(catalist)\n",
    "        maxlabel_num = 0\n",
    "        for i in labellist:\n",
    "            if catalist.count(i)> maxlabel_num:\n",
    "                maxlabel_num = catalist.count(i)\n",
    "                maxlabel = i\n",
    "        return i\"\"\"\n",
    "        #witty way\n",
    "        item = dict([(catalist.count(i),i) for i in catalist])\n",
    "        return item[max(item.keys())]\n",
    "    \n",
    "    def built_tree(self,dataset,labels):\n",
    "        catalist = [data[-1] for data in dataset]\n",
    "        if catalist.count(catalist[0]) == len(catalist):\n",
    "            return catalist[0]\n",
    "        #if the dataset is just the label,then return the lable that appears the most\n",
    "        if len(dataset[0])==1:\n",
    "            return self.maxlabels(catalist)\n",
    "        bestfeat = self.getBestFeat(dataset)\n",
    "        bestfeatlabel = labels[bestfeat]\n",
    "        tree = {bestfeatlabel : {}}\n",
    "        del(labels[bestfeat])\n",
    "        subfeat = set([data[bestfeat] for data in dataset])\n",
    "        for i in subfeat:\n",
    "            sublabels = labels[:]\n",
    "            subdataset = self.split_dataset(dataset,bestfeat,i)\n",
    "            subtree = self.built_tree(subdataset,sublabels)\n",
    "            tree[bestfeatlabel][i] = subtree\n",
    "        return tree\n",
    "    def train(self):\n",
    "        labels = copy.deepcopy(self.labels)\n",
    "        self.tree = self.built_tree(self.dataset,labels)\n",
    "        \n",
    "dtree = decision_tree()\n",
    "dtree.load_dataset(\"dataset.dat\",[\"age\",\"revenue\",\"student\",\"credit\"])\n",
    "dtree.train()\n",
    "print(dtree.tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''naive bayes'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
